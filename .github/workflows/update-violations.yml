name: Refresh drone-violations data

on:
  # Manual trigger from the Actions tab
  workflow_dispatch:

  # Automatic run every Monday at 03:00 UTC
  schedule:
    - cron: '0 3 * * 1'

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      # 1 Checkout the repo
      - uses: actions/checkout@v4

      # 2 Set up Python
      - uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      # 3 Install deps & run the scraper script
      - name: Run scraper
        run: |
          python -m pip install --quiet requests beautifulsoup4
          python scripts/update_violations.py   # writes data/violations.json

      # 4 Stage the JSON, commit only if it changed, then push
      - name: Commit & push if changed
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git config user.name  "github-actions"
          git config user.email "actions@users.noreply.github.com"

          # Stage the output file before comparing
          git add data/violations.json

          # If no diff in the index, skip; otherwise commit & push
          if git diff --cached --quiet; then
            echo "No changes â€” skipping commit."
          else
            git commit -m "auto: refresh violations data"
            git push
          fi
